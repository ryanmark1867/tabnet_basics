{"cells":[{"cell_type":"markdown","metadata":{"id":"YIeBggbihZkZ"},"source":["# NYC Airbnb Price Prediction - TabNet model training\n","\n","Use dataset published by Kaggle - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data - to train a simple TabNet model to predict prices for Airbnb properties.\n","\n","This notebook contains the code to train the model from the dataset prepared in the [data cleanup](https://github.com/ryanmark1867/fastai_basics/blob/master/notebooks/data_cleanup.ipynb) notebook. It is adapted from the [Keras model training notebook](https://github.com/ryanmark1867/deep_learning_basics/blob/master/notebooks/model_training.ipynb) trained on the same dataset. The TabNet aspects of this notebook were adapted from the here: [https://www.geeksforgeeks.org/tabnet/](https://www.geeksforgeeks.org/tabnet/).\n"]},{"cell_type":"markdown","metadata":{"id":"DlRfewg3hZkg"},"source":["# Links to key parts of the notebook <a name='linkanchor' />\n","<a href=#ingestdash>Ingest data</a>\n","\n","<a href=#buildpipe>Build pipeline</a>\n","\n","<a href=#modelfit>Define and fit model</a>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sEt7qZr7hZkh"},"source":["# Common imports and global variable definitions"]},{"cell_type":"code","source":["\n","''' check to see if the notebook is being run in Colab, and if so, set the current directory appropriately'''\n","if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/machine_learning_tabular_book/code/tabnet_basics/notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gH8To-DKhoMZ","executionInfo":{"status":"ok","timestamp":1666663916149,"user_tz":240,"elapsed":3458,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"a3cb91eb-6f03-4ca6-a27c-57e8e832d0a3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/machine_learning_tabular_book/code/tabnet_basics/notebooks\n"]}]},{"cell_type":"code","source":["import time\n","start_time = time.time()"],"metadata":{"id":"sFs8nj9ynE4S","executionInfo":{"status":"ok","timestamp":1666663916151,"user_tz":240,"elapsed":34,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# TabNet imports\n","! pip install pytorch-tabnet\n","import torch\n","from pytorch_tabnet.tab_model import TabNetClassifier"],"metadata":{"id":"uP7LvxOo0BrD","executionInfo":{"status":"ok","timestamp":1666663922333,"user_tz":240,"elapsed":6214,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a0606b1-ced9-4a78-bcbf-d3b70c2b76a5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.7/dist-packages (4.0)\n","Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.64.1)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.7.3)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.0.2)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.21.6)\n","Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.12.1+cu113)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.2.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.1.1)\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qMOg5J2MhZki","executionInfo":{"status":"ok","timestamp":1666663922340,"user_tz":240,"elapsed":92,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["# common imports\n","import zipfile\n","import pandas as pd\n","import numpy as np\n","import time\n","import seaborn as sns\n","from matplotlib import pyplot\n","# import datetime, timedelta\n","import datetime\n","import pydotplus\n","from datetime import datetime, timedelta\n","from datetime import date\n","from dateutil import relativedelta\n","from io import StringIO\n","import pandas as pd\n","import pickle\n","from pickle import dump\n","from pickle import load\n","from sklearn.base import BaseEstimator\n","from sklearn.base import TransformerMixin\n","# DSX code to import uploaded documents\n","from io import StringIO\n","import requests\n","import json\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import os\n","import yaml\n","import math\n","import sys\n","from subprocess import check_output\n","from IPython.display import display\n","#model libraries\n","\n","#from datetime import date\n","from sklearn import metrics\n","# import pipeline libraries\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import average_precision_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.base import TransformerMixin\n","from sklearn.base import BaseEstimator\n","from custom_classes import encode_categorical\n","from custom_classes import prep_for_keras_input\n","from custom_classes import fill_empty\n","from custom_classes import encode_text"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPDRPSYRhZkp","executionInfo":{"status":"ok","timestamp":1666663922342,"user_tz":240,"elapsed":90,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"48f8dcf0-6e9a-4127-e3f4-946786a96e42"},"outputs":[{"output_type":"stream","name":"stdout","text":["current directory is: /content/drive/MyDrive/machine_learning_tabular_book/code/tabnet_basics/notebooks\n","path_to_yaml /content/drive/MyDrive/machine_learning_tabular_book/code/tabnet_basics/notebooks/model_training_config.yml\n"]}],"source":["# load config file\n","current_path = os.getcwd()\n","print(\"current directory is: \"+current_path)\n","\n","path_to_yaml = os.path.join(current_path, 'model_training_config.yml')\n","print(\"path_to_yaml \"+path_to_yaml)\n","try:\n","    with open (path_to_yaml, 'r') as c_file:\n","        config = yaml.safe_load(c_file)\n","except Exception as e:\n","    print('Error reading the config file')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ukTsqXUAhZkr","executionInfo":{"status":"ok","timestamp":1666663922343,"user_tz":240,"elapsed":75,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"0d52ae18-3455-41a8-cb7f-446e6f7ac183"},"outputs":[{"output_type":"stream","name":"stdout","text":["date today 2022-10-25 02:11:58.775023\n"]}],"source":["# load parameters\n","\n","repeatable_run = config['test_parms']['repeatable_run']\n","# fix seeds to get identical results on mulitiple runs\n","if repeatable_run:\n","    from numpy.random import seed\n","    seed(4)\n","    tf.random.set_seed(7)\n","\n","\n","testproportion = config['test_parms']['testproportion'] # proportion of data reserved for test set\n","trainproportion = config['test_parms']['trainproportion'] # proportion of non-test data dedicated to training (vs. validation)\n","get_test_train_acc = config['test_parms']['get_test_train_acc']\n","verboseout = config['general']['verboseout']\n","includetext = config['general']['includetext'] # switch to determine whether text columns are included in the model\n","save_model_plot = config['general']['save_model_plot'] # switch to determine whether to generate plot with plot_model\n","tensorboard_callback = config['general']['tensorboard_callback'] # switch to determine if tensorboard callback defined\n","\n","presaved = config['general']['presaved']\n","savemodel = config['general']['savemodel']\n","picklemodel = config['general']['picklemodel']\n","hctextmax = config['general']['hctextmax']\n","maxwords = config['general']['maxwords']\n","textmax = config['general']['textmax']\n","\n","targetthresh = config['general']['targetthresh']\n","targetcontinuous = config['general']['targetcontinuous']\n","target_col = config['general']['target_col']\n","\n","#time of day thresholds\n","time_of_day = {'overnight':{'start':0,'end':5},'morning_rush':{'start':5,'end':10},\n","              'midday':{'start':10,'end':15},'aft_rush':{'start':15,'end':19},'evening':{'start':19,'end':24}}\n","\n","\n","\n","emptythresh = config['general']['emptythresh']\n","zero_weight = config['general']['zero_weight']\n","one_weight = config['general']['one_weight']\n","one_weight_offset = config['general']['one_weight_offset']\n","patience_threshold = config['general']['patience_threshold']\n","\n","\n","# modifier for saved model elements\n","modifier = config['general']['modifier']\n","\n","# control whether training controlled by early stop\n","early_stop = True\n","\n","# default hyperparameter values\n","learning_rate = config['hyperparameters']['learning_rate']\n","dropout_rate = config['hyperparameters']['dropout_rate']\n","l2_lambda = config['hyperparameters']['l2_lambda']\n","loss_func = config['hyperparameters']['loss_func']\n","output_activation = config['hyperparameters']['output_activation']\n","batch_size = config['hyperparameters']['batch_size']\n","epochs = config['hyperparameters']['epochs']\n","\n","# date values\n","date_today = datetime.now()\n","print(\"date today\",date_today)\n","\n","# pickled original dataset and post-preprocessing dataset\n","pickled_data_file = config['general']['pickled_data_file']\n","pickled_dataframe = config['general']['pickled_dataframe']\n","\n","# experiment parameter\n","\n","current_experiment = config['test_parms']['current_experiment']\n","\n","# load lists of column categories\n","collist = config['categorical']\n","textcols = config['text']\n","continuouscols = config['continuous']\n","excludefromcolist = config['excluded']"]},{"cell_type":"markdown","metadata":{"id":"LHOm49gThZku"},"source":["# Helper functions"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gID1ffP6hZkw","executionInfo":{"status":"ok","timestamp":1666663922344,"user_tz":240,"elapsed":65,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["# time_of_day = {'overnight':{'start':0,'end':5},'morning_rush':{'start':5,'end':10},\n","#              'midday':{'start':10,'end':15},'aft_rush':{'start':15,'end':19},'evening':{'start':19,'end':23}}\n","\n","\n","def get_time(hour):\n","    for tod in time_of_day:\n","        if (hour >= time_of_day[tod]['start']) and (hour < time_of_day[tod]['end']):\n","            tod_out = tod\n","    return(tod_out)\n","\n","def weekend_time(day, tod):\n","    if (day=='Saturday') or (day=='Sunday'):\n","        return('w'+tod)\n","    else:\n","        return(tod)\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"f7O0zkMphZky","executionInfo":{"status":"ok","timestamp":1666663922345,"user_tz":240,"elapsed":65,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["# get the paths required\n","\n","def get_path():\n","    '''get the path for data files\n","\n","    Returns:\n","        path: path for data files\n","    '''\n","    rawpath = os.getcwd()\n","    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n","    path = os.path.abspath(os.path.join(rawpath, '..', 'data'))\n","    return(path)\n","\n","def get_pipeline_path():\n","    '''get the path for data files\n","    \n","    Returns:\n","        path: path for pipeline files\n","    '''\n","    rawpath = os.getcwd()\n","    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n","    path = os.path.abspath(os.path.join(rawpath, '..', 'pipelines'))\n","    return(path)\n","\n","def get_model_path():\n","    '''get the path for data files\n","    \n","    Returns:\n","        path: path for model files\n","    '''\n","    rawpath = os.getcwd()\n","    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n","    path = os.path.abspath(os.path.join(rawpath, '..', 'models'))\n","    return(path)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"UHr7ftVJhZkz","executionInfo":{"status":"ok","timestamp":1666663922346,"user_tz":240,"elapsed":65,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["def set_experiment_parameters(experiment_number, count_no_delay, count_delay):\n","    ''' set the appropriate parameters for the experiment \n","    Args:\n","        experiment_number: filename containing config parameters\n","        count_no_delay: count of negative outcomes in the dataset\n","        count_delay: count of positive outcomes in the dataset\n","\n","    Returns:\n","        early_stop: whether the experiment includes an early stop callback\n","        one_weight: weight applied to positive outcomes\n","        epochs: number of epochs in the experiment\n","        es_monitor: performance measurement tracked in callbacks\n","        es_mod: direction of performance being tracked in callbacks\n","    \n","    '''\n","    print(\"setting parameters for experiment \", experiment_number)\n","    # default settings for early stopping:\n","    es_monitor = \"val_loss\"\n","    es_mode = \"min\"\n","    if experiment_number == 0:\n","        #\n","        early_stop = False\n","        #\n","        one_weight = 1.0\n","        #\n","        epochs = 1\n","    elif experiment_number == 9:\n","        #\n","        early_stop = True\n","        es_monitor=\"val_accuracy\"\n","        es_mode = \"max\"\n","        #\n","        one_weight = (count_no_delay/count_delay) + one_weight_offset\n","        #\n","        get_test_train_acc = False\n","        #\n","        epochs = 20    \n","    elif experiment_number == 1:\n","        #\n","        early_stop = False\n","        #\n","        one_weight = 1.0\n","        #\n","        epochs = 10\n","    elif experiment_number == 2:\n","        #\n","        early_stop = False\n","        #\n","        one_weight = 1.0\n","        #\n","        epochs = 50\n","    elif experiment_number == 3:\n","        #\n","        early_stop = False\n","        #\n","        one_weight = (count_no_delay/count_delay) + one_weight_offset\n","        #\n","        epochs = 50\n","    elif experiment_number == 4:\n","        #\n","        early_stop = True\n","        es_monitor = \"val_loss\"\n","        es_mode = \"min\"\n","        #\n","        one_weight = (count_no_delay/count_delay) + one_weight_offset\n","        #\n","        epochs = 50\n","    elif experiment_number == 5:\n","        #\n","        early_stop = True\n","        # if early stopping fails because the level of TensorFlow/Python, comment out the following\n","        # line and uncomment the subsequent if statement\n","        es_monitor=\"val_accuracy\"\n","        '''\n","        if sys.version_info >= (3,7):\n","            es_monitor=\"val_accuracy\"\n","        else:\n","            es_monitor = \"val_acc\"\n","        '''\n","        es_mode = \"max\"\n","        #\n","        one_weight = (count_no_delay/count_delay) + one_weight_offset\n","        #\n","        epochs = 50\n","    else:\n","        early_stop = True\n","    return(early_stop, one_weight, epochs,es_monitor,es_mode)\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"g-Qgt5J-hZk0"},"source":["# Ingest data and create refactored dataframe <a name='ingestdash' />\n","- Ingest data for route information and delay information\n","- Create refactored dataframe with one row per route / direction / timeslot combination\n","\n","\n","<a href=#linkanchor>Back to link list</a>"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"DgI5ZiUShZk1","executionInfo":{"status":"ok","timestamp":1666663922352,"user_tz":240,"elapsed":70,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["def ingest_data(path):\n","    '''load list of valid routes and directions into dataframe\n","    Args:\n","        path: path for data files\n","    \n","    Returns:\n","        merged_data: dataframe loaded from pickle file\n","    '''\n","    file_name = os.path.join(path,pickled_dataframe)\n","    merged_data = pd.read_pickle(file_name)\n","    merged_data.head()\n","    return(merged_data)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"eUn9rPCdhZk1","executionInfo":{"status":"ok","timestamp":1666663922362,"user_tz":240,"elapsed":79,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["def prep_merged_data(merged_data,target_col):\n","    '''add derived columns to merged_data dataframe\n","    Args:\n","        merged_data: input dataframe\n","        target_col: column that is the target\n","    \n","    Returns:\n","        merged_data: dataframe with derived columns added\n","    '''\n","    if targetcontinuous:\n","        merged_data['target'] = merged_data[target_col]\n","    else:\n","        merged_data['target'] = np.where(merged_data[target_col] >= merged_data[target_col].mean(), 1, 0 )\n","    return(merged_data)"]},{"cell_type":"markdown","metadata":{"id":"w4-DJIY8hZk2"},"source":["# Master Prep Cell\n","Contains calls to functions to load data, prep input dataframes, and create refactored dataframe"]},{"cell_type":"code","execution_count":12,"metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/"},"id":"P_unjf8hhZk3","executionInfo":{"status":"ok","timestamp":1666663922368,"user_tz":240,"elapsed":85,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"856034c7-b3a5-48ff-f81f-e550f90ada8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["path is /content/drive/MyDrive/machine_learning_tabular_book/code/tabnet_basics/data\n","shape of pre refactored dataset (48895, 18)\n","shape of refactored dataset (48895, 18)\n","count under mean  34016\n","count over mean  14879\n","setting parameters for experiment  0\n","early_stop is  False\n","one_weight is  1.0\n","epochs is  1\n","es_monitor is  val_loss\n","es_mode is  min\n"]}],"source":["path = get_path()\n","print(\"path is\",path)\n","# load route direction and delay data datframes\n","merged_data = ingest_data(path)\n","merged_data = prep_merged_data(merged_data,target_col)\n","print(\"shape of pre refactored dataset\", merged_data.shape)\n","#merged_data['year'].value_counts()\n","#merged_data.groupby(['Route','Direction']).size().reset_index().rename(columns={0:'count'}).tail(50)\n","# create refactored dataframe with one row for each route / direction / timeslot combination\n","print(\"shape of refactored dataset\", merged_data.shape)\n","count_no_delay = merged_data[merged_data['target']==0].shape[0]\n","count_delay = merged_data[merged_data['target']==1].shape[0]\n","print(\"count under mean \",count_no_delay)\n","print(\"count over mean \",count_delay)\n","# define parameters for the current experiment\n","experiment_number = current_experiment\n","early_stop, one_weight, epochs,es_monitor,es_mode = set_experiment_parameters(experiment_number, count_no_delay, count_delay)\n","print(\"early_stop is \",early_stop)\n","print(\"one_weight is \",one_weight)\n","print(\"epochs is \",epochs)\n","print(\"es_monitor is \",es_monitor)\n","print(\"es_mode is \",es_mode)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xpjyG_hhZk3","executionInfo":{"status":"ok","timestamp":1666663922370,"user_tz":240,"elapsed":79,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"a6f13b97-7fad-4aeb-89f1-7e5eb65ac8c5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(48895, 18)"]},"metadata":{},"execution_count":13}],"source":["merged_data.shape"]},{"cell_type":"code","source":["merged_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":372},"id":"g7rUQJH-7efD","executionInfo":{"status":"ok","timestamp":1666663922371,"user_tz":240,"elapsed":73,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"694bf51b-0dbc-41e5-909e-644af08f08d0"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     id                                              name  host_id  \\\n","0  2539                Clean & quiet apt home by the park     2787   \n","1  2595                             Skylit Midtown Castle     2845   \n","2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n","3  3831                   Cozy Entire Floor of Brownstone     4869   \n","4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n","\n","     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n","0         John            Brooklyn    Kensington  40.64749  -73.97237   \n","1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n","2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n","3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n","4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n","\n","         room_type  price  minimum_nights  number_of_reviews last_review  \\\n","0     Private room    149               1                  9  2018-10-19   \n","1  Entire home/apt    225               1                 45  2019-05-21   \n","2     Private room    150               3                  0  2019-01-01   \n","3  Entire home/apt     89               1                270  2019-07-05   \n","4  Entire home/apt     80              10                  9  2018-11-19   \n","\n","   reviews_per_month  calculated_host_listings_count  availability_365  \\\n","0               0.21                               6               365   \n","1               0.38                               2               355   \n","2               0.00                               1               365   \n","3               4.64                               1               194   \n","4               0.10                               1                 0   \n","\n","   (latitude, longitude)  target  \n","0  (40.64749, -73.97237)       0  \n","1  (40.75362, -73.98377)       1  \n","2   (40.80902, -73.9419)       0  \n","3  (40.68514, -73.95976)       0  \n","4  (40.79851, -73.94399)       0  "],"text/html":["\n","  <div id=\"df-3b9c8843-81ae-410a-9f4d-f6fe36eaccce\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>name</th>\n","      <th>host_id</th>\n","      <th>host_name</th>\n","      <th>neighbourhood_group</th>\n","      <th>neighbourhood</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>room_type</th>\n","      <th>price</th>\n","      <th>minimum_nights</th>\n","      <th>number_of_reviews</th>\n","      <th>last_review</th>\n","      <th>reviews_per_month</th>\n","      <th>calculated_host_listings_count</th>\n","      <th>availability_365</th>\n","      <th>(latitude, longitude)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2539</td>\n","      <td>Clean &amp; quiet apt home by the park</td>\n","      <td>2787</td>\n","      <td>John</td>\n","      <td>Brooklyn</td>\n","      <td>Kensington</td>\n","      <td>40.64749</td>\n","      <td>-73.97237</td>\n","      <td>Private room</td>\n","      <td>149</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>2018-10-19</td>\n","      <td>0.21</td>\n","      <td>6</td>\n","      <td>365</td>\n","      <td>(40.64749, -73.97237)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2595</td>\n","      <td>Skylit Midtown Castle</td>\n","      <td>2845</td>\n","      <td>Jennifer</td>\n","      <td>Manhattan</td>\n","      <td>Midtown</td>\n","      <td>40.75362</td>\n","      <td>-73.98377</td>\n","      <td>Entire home/apt</td>\n","      <td>225</td>\n","      <td>1</td>\n","      <td>45</td>\n","      <td>2019-05-21</td>\n","      <td>0.38</td>\n","      <td>2</td>\n","      <td>355</td>\n","      <td>(40.75362, -73.98377)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3647</td>\n","      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n","      <td>4632</td>\n","      <td>Elisabeth</td>\n","      <td>Manhattan</td>\n","      <td>Harlem</td>\n","      <td>40.80902</td>\n","      <td>-73.94190</td>\n","      <td>Private room</td>\n","      <td>150</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2019-01-01</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>365</td>\n","      <td>(40.80902, -73.9419)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3831</td>\n","      <td>Cozy Entire Floor of Brownstone</td>\n","      <td>4869</td>\n","      <td>LisaRoxanne</td>\n","      <td>Brooklyn</td>\n","      <td>Clinton Hill</td>\n","      <td>40.68514</td>\n","      <td>-73.95976</td>\n","      <td>Entire home/apt</td>\n","      <td>89</td>\n","      <td>1</td>\n","      <td>270</td>\n","      <td>2019-07-05</td>\n","      <td>4.64</td>\n","      <td>1</td>\n","      <td>194</td>\n","      <td>(40.68514, -73.95976)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5022</td>\n","      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n","      <td>7192</td>\n","      <td>Laura</td>\n","      <td>Manhattan</td>\n","      <td>East Harlem</td>\n","      <td>40.79851</td>\n","      <td>-73.94399</td>\n","      <td>Entire home/apt</td>\n","      <td>80</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>2018-11-19</td>\n","      <td>0.10</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>(40.79851, -73.94399)</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b9c8843-81ae-410a-9f4d-f6fe36eaccce')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b9c8843-81ae-410a-9f4d-f6fe36eaccce button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b9c8843-81ae-410a-9f4d-f6fe36eaccce');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"CAz0ZvIghZk4"},"source":["# Define training, validation, and test subsets of the dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"z1WjDwUdhZk4","executionInfo":{"status":"ok","timestamp":1666663922375,"user_tz":240,"elapsed":75,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["def get_train_validation_test(dataset):\n","    '''get training and test data set\n","    Args:\n","        dataset: input dataframe\n","    \n","    Returns:\n","        dtrain: training subset of dataset\n","        dvalid: validation subset of dataset\n","        dtest: test subset of dataset\n","    '''\n","    train, test = train_test_split(dataset, test_size = testproportion)\n","    dtrain, dvalid = train_test_split(train, random_state=123, train_size=trainproportion)\n","    print(\"Through train test split. Test proportion:\")\n","    print(testproportion)\n","    return(dtrain,dvalid,test)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vsT0IecPhZk5"},"source":["# Build Pipeline <a name='buildpipe' />\n","\n","Create pipeline objects to perform final data preparation steps for training and inference.\n","\n","Note that cleanup on the training dataset is completed upstream in the [data cleanup notebook](https://github.com/ryanmark1867/end_to_end_deep_learning_liveproject/blob/master/notebooks/data_cleanup.ipynb). \n","- The pipelines only accomplish the subset of preparation that is required for both training and inference\n","- Because the scoring data coming in for inference is forced by the web deployment to avoid the invalid values that the data cleanup notebook deals with, the pipelines don't have to deal with those problems.\n","\n","<a href=#linkanchor>Back to link list</a>"]},{"cell_type":"code","source":["# Features are\n","# neighbourhood_group\n","# neighbourhood\n","# room_type\n","# minimum_nights\n","# number_of_reviews\n","# reviews_per_month\n","# calculated_host_listings_count\n","\n"],"metadata":{"id":"XFfTDWwlKf-K","executionInfo":{"status":"ok","timestamp":1666663922380,"user_tz":240,"elapsed":79,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# master block to invoke pipeline\n","\n","# build fully qualified names for the files for saving the pipelines\n","pipeline_path = get_pipeline_path()\n","pipeline1_file_name = os.path.join(pipeline_path,'sc_delay_pipleline'+modifier+'.pkl')\n","pipeline2_file_name = os.path.join(pipeline_path,'sc_delay_pipleline_keras_prep'+modifier+'.pkl')\n","\n","# define column lists:\n","# collist,continuouscols,textcols = def_col_lists()\n","\n","# create objects of the pipeline classes\n","fe = fill_empty()\n","ec = encode_categorical()\n","pk = prep_for_keras_input()\n","pk_valid = prep_for_keras_input()\n","pk_test = prep_for_keras_input()\n","\n","# need to implement the pipeline in two parts:\n","# 1. fill empty + encode categoricals\n","# 2. prep for Keras\n","# because part 1 needs to be applied to the entire dataset and part 2 to the individual train, validate, and test sets\n","\n","\n","sc_delay_pipeline = Pipeline([('fill_empty',fe),('encode_categorical',ec)])\n","# need to have distinct pipeline objects for each subset of the dataset: train, validated and test\n","sc_delay_pipeline_keras_prep = Pipeline([('prep_for_keras',pk)])\n","sc_delay_pipeline_keras_prep_valid = Pipeline([('prep_for_keras',pk_valid)])\n","sc_delay_pipeline_keras_prep_test = Pipeline([('prep_for_keras',pk_test)])\n","\n","# provide the value for each parameter of each of the pipeline classes\n","\n","sc_delay_pipeline.set_params(fill_empty__collist = collist, fill_empty__continuouscols = continuouscols,\n","                            fill_empty__textcols = textcols,encode_categorical__col_list = collist)\n","sc_delay_pipeline_keras_prep.set_params(prep_for_keras__collist = collist,\n","                            prep_for_keras__continuouscols = continuouscols,\n","                            prep_for_keras__textcols = textcols)\n","sc_delay_pipeline_keras_prep_valid.set_params(prep_for_keras__collist = collist,\n","                            prep_for_keras__continuouscols = continuouscols,\n","                            prep_for_keras__textcols = textcols)\n","sc_delay_pipeline_keras_prep_test.set_params(prep_for_keras__collist = collist,\n","                            prep_for_keras__continuouscols = continuouscols,\n","                            prep_for_keras__textcols = textcols)\n","\n","# fit the input dataset to the pipeline\n","\n","# first fit the first segment of pipeline on the whole dataset\n","X = sc_delay_pipeline.fit_transform(merged_data)\n","max_dict = ec.max_dict\n","# then split dataset\n","dump(sc_delay_pipeline, open(pipeline1_file_name,'wb'))\n","dump(sc_delay_pipeline_keras_prep, open(pipeline2_file_name,'wb'))\n","dtrain, dvalid, test = get_train_validation_test(X)\n","# then apply second portion of pipeline to each subset\n","# need to have a distinct object for each to prevent first object impacting others\n","\n","X_train_list = sc_delay_pipeline_keras_prep.fit_transform(dtrain)\n","X_valid_list = sc_delay_pipeline_keras_prep_valid.fit_transform(dvalid)\n","X_test_list = sc_delay_pipeline_keras_prep_test.fit_transform(test)\n","\n","print(\"keras variables defined\")\n","print(\"X_train_list\",X_train_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAbTH9rz-dZA","executionInfo":{"status":"ok","timestamp":1666663922380,"user_tz":240,"elapsed":78,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"056be295-ff4b-4e5f-ae06-cd7323713253"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["fill empty xform\n","col is  neighbourhood_group\n","col is  neighbourhood\n","col is  room_type\n","transform col is  neighbourhood_group\n","after transform col is  neighbourhood_group\n","transform col is  neighbourhood\n","after transform col is  neighbourhood\n","transform col is  room_type\n","after transform col is  room_type\n","Through train test split. Test proportion:\n","0.2\n","cat col is neighbourhood_group\n","cat col is neighbourhood\n","cat col is room_type\n","cont col is minimum_nights\n","cont col is number_of_reviews\n","cont col is reviews_per_month\n","cont col is calculated_host_listings_count\n","cat col is neighbourhood_group\n","cat col is neighbourhood\n","cat col is room_type\n","cont col is minimum_nights\n","cont col is number_of_reviews\n","cont col is reviews_per_month\n","cont col is calculated_host_listings_count\n","cat col is neighbourhood_group\n","cat col is neighbourhood\n","cat col is room_type\n","cont col is minimum_nights\n","cont col is number_of_reviews\n","cont col is reviews_per_month\n","cont col is calculated_host_listings_count\n","keras variables defined\n","X_train_list [array([1, 2, 2, ..., 2, 1, 1]), array([214,  34,  64, ...,  73, 182,  28]), array([0, 1, 1, ..., 0, 0, 1]), array([1, 1, 2, ..., 2, 3, 5]), array([ 57,  63,   9, ...,   9, 118,   3]), array([7.04, 2.34, 0.16, ..., 2.43, 2.07, 0.27]), array([  2,   4,   2, ..., 327,   1,   1])]\n"]}]},{"cell_type":"code","source":["merged_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":372},"id":"So_s9tZhOyXZ","executionInfo":{"status":"ok","timestamp":1666663922381,"user_tz":240,"elapsed":70,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"81054d8c-7e26-4c04-c9c5-5376cf51795e"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     id                                              name  host_id  \\\n","0  2539                Clean & quiet apt home by the park     2787   \n","1  2595                             Skylit Midtown Castle     2845   \n","2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n","3  3831                   Cozy Entire Floor of Brownstone     4869   \n","4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n","\n","     host_name  neighbourhood_group  neighbourhood  latitude  longitude  \\\n","0         John                    1            108  40.64749  -73.97237   \n","1     Jennifer                    2            127  40.75362  -73.98377   \n","2    Elisabeth                    2             94  40.80902  -73.94190   \n","3  LisaRoxanne                    1             41  40.68514  -73.95976   \n","4        Laura                    2             61  40.79851  -73.94399   \n","\n","   room_type  price  minimum_nights  number_of_reviews last_review  \\\n","0          1    149               1                  9  2018-10-19   \n","1          0    225               1                 45  2019-05-21   \n","2          1    150               3                  0  2019-01-01   \n","3          0     89               1                270  2019-07-05   \n","4          0     80              10                  9  2018-11-19   \n","\n","   reviews_per_month  calculated_host_listings_count  availability_365  \\\n","0               0.21                               6               365   \n","1               0.38                               2               355   \n","2               0.00                               1               365   \n","3               4.64                               1               194   \n","4               0.10                               1                 0   \n","\n","   (latitude, longitude)  target  \n","0  (40.64749, -73.97237)       0  \n","1  (40.75362, -73.98377)       1  \n","2   (40.80902, -73.9419)       0  \n","3  (40.68514, -73.95976)       0  \n","4  (40.79851, -73.94399)       0  "],"text/html":["\n","  <div id=\"df-138386c7-13f0-4d9a-b570-39e61c0ef92d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>name</th>\n","      <th>host_id</th>\n","      <th>host_name</th>\n","      <th>neighbourhood_group</th>\n","      <th>neighbourhood</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>room_type</th>\n","      <th>price</th>\n","      <th>minimum_nights</th>\n","      <th>number_of_reviews</th>\n","      <th>last_review</th>\n","      <th>reviews_per_month</th>\n","      <th>calculated_host_listings_count</th>\n","      <th>availability_365</th>\n","      <th>(latitude, longitude)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2539</td>\n","      <td>Clean &amp; quiet apt home by the park</td>\n","      <td>2787</td>\n","      <td>John</td>\n","      <td>1</td>\n","      <td>108</td>\n","      <td>40.64749</td>\n","      <td>-73.97237</td>\n","      <td>1</td>\n","      <td>149</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>2018-10-19</td>\n","      <td>0.21</td>\n","      <td>6</td>\n","      <td>365</td>\n","      <td>(40.64749, -73.97237)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2595</td>\n","      <td>Skylit Midtown Castle</td>\n","      <td>2845</td>\n","      <td>Jennifer</td>\n","      <td>2</td>\n","      <td>127</td>\n","      <td>40.75362</td>\n","      <td>-73.98377</td>\n","      <td>0</td>\n","      <td>225</td>\n","      <td>1</td>\n","      <td>45</td>\n","      <td>2019-05-21</td>\n","      <td>0.38</td>\n","      <td>2</td>\n","      <td>355</td>\n","      <td>(40.75362, -73.98377)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3647</td>\n","      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n","      <td>4632</td>\n","      <td>Elisabeth</td>\n","      <td>2</td>\n","      <td>94</td>\n","      <td>40.80902</td>\n","      <td>-73.94190</td>\n","      <td>1</td>\n","      <td>150</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2019-01-01</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>365</td>\n","      <td>(40.80902, -73.9419)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3831</td>\n","      <td>Cozy Entire Floor of Brownstone</td>\n","      <td>4869</td>\n","      <td>LisaRoxanne</td>\n","      <td>1</td>\n","      <td>41</td>\n","      <td>40.68514</td>\n","      <td>-73.95976</td>\n","      <td>0</td>\n","      <td>89</td>\n","      <td>1</td>\n","      <td>270</td>\n","      <td>2019-07-05</td>\n","      <td>4.64</td>\n","      <td>1</td>\n","      <td>194</td>\n","      <td>(40.68514, -73.95976)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5022</td>\n","      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n","      <td>7192</td>\n","      <td>Laura</td>\n","      <td>2</td>\n","      <td>61</td>\n","      <td>40.79851</td>\n","      <td>-73.94399</td>\n","      <td>0</td>\n","      <td>80</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>2018-11-19</td>\n","      <td>0.10</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>(40.79851, -73.94399)</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-138386c7-13f0-4d9a-b570-39e61c0ef92d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-138386c7-13f0-4d9a-b570-39e61c0ef92d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-138386c7-13f0-4d9a-b570-39e61c0ef92d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["##Define and fit model <a name='modelfit' />\n","- use the unique fastai tabular data capabilities\n","\n","<a href=#linkanchor>Back to link list</a>"],"metadata":{"id":"Y3gWLj4xTURi"}},{"cell_type":"code","source":["# get lists of lists for the training and test datasets\n","list_of_lists_train = []\n","list_of_lists_test = []\n","list_of_lists_valid = []\n","for i in range(0,7):\n","    list_of_lists_train.append(X_train_list[i].tolist())\n","    list_of_lists_valid.append(X_valid_list[i].tolist())\n","    list_of_lists_test.append(X_test_list[i].tolist())"],"metadata":{"id":"av-IJJRnAa2b","executionInfo":{"status":"ok","timestamp":1666663922383,"user_tz":240,"elapsed":69,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["%%time\n","# convert lists of lists to numpy arrays of lists\n","X_train = np.array(list_of_lists_train).T\n","X_valid = np.array(list_of_lists_valid).T\n","X_test = np.array(list_of_lists_test).T\n","y_train = dtrain.target\n","y_valid = dvalid.target\n","y_test = test.target"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXZHVOdxA78U","executionInfo":{"status":"ok","timestamp":1666663922384,"user_tz":240,"elapsed":69,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"000e0ad6-afa9-44ea-bcfd-c0730329e57d"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 19.9 ms, sys: 0 ns, total: 19.9 ms\n","Wall time: 19.8 ms\n"]}]},{"cell_type":"code","source":["# define TabularDataLoaders object using the dataframe, the list of pre-processing steps, the categorical and continuous\n","# column lists\n","# valid_idx: the indices to use for the validation set\n","\n","tb_cls = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n","                    optimizer_params=dict(lr=1e-3),\n","                    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n","                    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n","                    mask_type='entmax' # \"sparsemax\"\n","                    )\n","tb_cls.fit(X_train, y_train,\n","               eval_set=[(X_train, y_train), (X_valid, y_valid)],\n","               eval_name=['train', 'valid'],\n","               eval_metric=['accuracy'],\n","               max_epochs=10 , patience=3,\n","               batch_size=28, drop_last=False) "],"metadata":{"id":"DIvJckly9eLH","executionInfo":{"status":"ok","timestamp":1666664255103,"user_tz":240,"elapsed":332781,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"40e68070-78cd-4396-9db7-1de3fd213a0a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.51082 | train_accuracy: 0.77914 | valid_accuracy: 0.78464 |  0:00:37s\n","epoch 1  | loss: 0.45767 | train_accuracy: 0.78534 | valid_accuracy: 0.7854  |  0:01:09s\n","epoch 2  | loss: 0.44978 | train_accuracy: 0.78665 | valid_accuracy: 0.78502 |  0:01:41s\n","epoch 3  | loss: 0.44584 | train_accuracy: 0.791   | valid_accuracy: 0.79128 |  0:02:13s\n","epoch 4  | loss: 0.44107 | train_accuracy: 0.79279 | valid_accuracy: 0.79358 |  0:02:46s\n","epoch 5  | loss: 0.4407  | train_accuracy: 0.79295 | valid_accuracy: 0.7955  |  0:03:17s\n","epoch 6  | loss: 0.4377  | train_accuracy: 0.79349 | valid_accuracy: 0.79499 |  0:03:49s\n","epoch 7  | loss: 0.43646 | train_accuracy: 0.79324 | valid_accuracy: 0.79461 |  0:04:21s\n","epoch 8  | loss: 0.43457 | train_accuracy: 0.79276 | valid_accuracy: 0.79614 |  0:04:53s\n","epoch 9  | loss: 0.43476 | train_accuracy: 0.79356 | valid_accuracy: 0.79461 |  0:05:24s\n","Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_valid_accuracy = 0.79614\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"code","source":["# exercise on the test set\n","predictions =[ '0' if i < 0.5 else '1' for i in tb_cls.predict(X_test)]"],"metadata":{"id":"1DaCHRrF2zWe","executionInfo":{"status":"ok","timestamp":1666664262679,"user_tz":240,"elapsed":7592,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["\n","# print elapsed time to run the notebook\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F71e5cmdnLM2","executionInfo":{"status":"ok","timestamp":1666664262681,"user_tz":240,"elapsed":32,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"9cb79edc-5c9d-4f87-de43-ecc7a5a587e2"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 342.8936278820038 seconds ---\n"]}]}],"metadata":{"kernelspec":{"display_name":"try_tf2","language":"python","name":"try_tf2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}